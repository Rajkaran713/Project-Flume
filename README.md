# Project-Flume
An AWS powered full fledged Realtime ELT Data Engineering project that extracts various json datasets from Canadian weather website, a public API (MSC GeoMet API), loads, transforms, forecasts and displays the future water levels in a dashboard for effective flood warning.


# ğŸŒŠ Project Flume - Real-Time Weather & Water Monitoring Platform

**End-to-end data engineering pipeline with ML-based flood prediction**

![Python](https://img.shields.io/badge/Python-3.12-blue)
![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20Lambda%20%7C%20EC2-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red)
![ML](https://img.shields.io/badge/ML-Forecasting-green)

---

## ğŸ“‹ Overview

Project Flume is a production-grade data engineering platform that ingests, processes, and analyzes real-time environmental data from **2,600+ monitoring stations** across Canada. The system combines weather and hydrometric data to predict water level changes and identify flood risks **6-24 hours in advance** using machine learning.

### Key Features

- ğŸ”„ **Real-time Data Ingestion**: Automated ETL pipeline processing 14GB+ daily from Environment Canada APIs
- âš¡ **Serverless Transformation**: AWS Lambda auto-transforms JSON â†’ Parquet with 10x compression
- ğŸ¯ **ML Forecasting**: Time-series models predict water levels 24 hours ahead with confidence intervals
- ğŸ“Š **Interactive Dashboard**: Streamlit-based visualization with 2,600+ stations and real-time alerts
- ğŸ—ï¸ **Medallion Architecture**: Bronze (raw) â†’ Silver (clean) â†’ Gold (aggregated) data layers

---

## ğŸ›ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATA SOURCES (Environment Canada)                           â”‚
â”‚ â€¢ SWOB (1,100+ weather stations)                            â”‚
â”‚ â€¢ Hydrometric (1,500+ water monitoring stations).           |
| â€¢ Climate_Hourly (Daily climate data)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INGESTION LAYER (EC2 + Docker)                              â”‚
â”‚ â€¢ Cron-based extraction every 5 minutes                     â”‚
â”‚ â€¢ Incremental state management                              â”‚
â”‚ â€¢ Partitioned S3 writes (year/month/day)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BRONZE LAYER (S3)                                           â”‚
â”‚ â€¢ Raw JSON files                                            â”‚
â”‚ â€¢ ~120MB per batch                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (S3 Event â†’ Lambda)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRANSFORMATION LAYER (AWS Lambda)                           â”‚
â”‚ â€¢ Event-driven processing (<1 sec latency)                  â”‚
â”‚ â€¢ JSON â†’ Parquet conversion (10x compression)               â”‚
â”‚ â€¢ Derived metrics (feels-like temp, wind chill)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SILVER LAYER (S3)                                           â”‚
â”‚ â€¢ Clean Parquet files (~5MB per batch)                      â”‚
â”‚ â€¢ Columnar storage for analytics                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GOLD LAYER (S3)                                             â”‚
â”‚ â€¢ Pre-aggregated tables:                                    â”‚
â”‚   - station_latest (current conditions)                     â”‚
â”‚   - hourly_summary (time series)                            â”‚
â”‚   - station_metadata (reference)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ML FORECASTING ENGINE                                       â”‚
â”‚ â€¢ Linear regression with time features                      â”‚
â”‚ â€¢ 24-hour water level predictions                           â”‚
â”‚ â€¢ Confidence intervals (95%)                                â”‚
â”‚ â€¢ Flood risk identification                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VISUALIZATION LAYER (Streamlit)                             â”‚
â”‚ â€¢ Interactive maps (Plotly)                                 â”‚
â”‚ â€¢ Real-time metrics & alerts                                â”‚
â”‚ â€¢ Historical + forecast charts                              â”‚
â”‚ â€¢ Auto-refresh every 5 minutes                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- AWS Account with S3, Lambda, EC2 access
- AWS CLI configured

### Installation
```bash
# Clone repository
git clone https://github.com/Rajkaran713/Project-Flume.git
cd Project-Flume

# Install dependencies
pip install -r requirements.txt
```

### Running the Dashboard Locally
```bash
cd flume-etl
streamlit run dashboard.py
```

---

## ğŸ“‚ Project Structure

```
Project-Flume/
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ producer.py              # EC2 data ingestion script
â”‚   â”œâ”€â”€ Dockerfile               # Container for EC2 deployment
â”‚   â””â”€â”€ requirements.txt         # Producer dependencies
â”œâ”€â”€ flume-etl/
â”‚   â”œâ”€â”€ lambda_transform.py      # Lambda transformation logic
â”‚   â”œâ”€â”€ create_gold_layer.py     # Gold layer aggregation
â”‚   â”œâ”€â”€ forecast_water_levels.py # ML forecasting engine
â”‚   â”œâ”€â”€ dashboard.py             # Streamlit visualization
â”‚   â””â”€â”€ transform_to_silver.py   # Silver layer processor
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â””â”€â”€ s3-data-lake/        # Custom reusable S3 module
â”‚   â”‚       â”œâ”€â”€ main.tf          # S3 bucket with data lake best practices
â”‚   â”‚       â”œâ”€â”€ variables.tf     # Module input variables
â”‚   â”‚       â””â”€â”€ outputs.tf       # Module outputs
â”‚   â”œâ”€â”€ main.tf                  # Root module orchestrating resources
â”‚   â”œâ”€â”€ provider.tf              # AWS provider configuration
â”‚   â”œâ”€â”€ variables.tf             # Root input variables
â”‚   â”œâ”€â”€ outputs.tf               # Infrastructure outputs
â”‚   â”œâ”€â”€ lambda.tf                # Lambda function configuration
â”‚   â”œâ”€â”€ iam.tf                   # IAM roles and policies
â”‚   â”œâ”€â”€ ec2.tf                   # EC2 instance (optional)
â”‚   â””â”€â”€ README.md                # Terraform documentation
â”œâ”€â”€ images/                      # Dashboard screenshots
â”‚   â”œâ”€â”€ dashboard-overview.png
â”‚   â”œâ”€â”€ weather-tab.png
â”‚   â””â”€â”€ water-forecast.png
â”œâ”€â”€ requirements.txt             # Main Python dependencies
â””â”€â”€ README.md                    # This file
```

---

## ğŸ’¡ Technical Highlights

### Data Engineering

- **Incremental Processing**: State management prevents duplicate ingestion
- **Partitioning Strategy**: Hive-style partitioning (year/month/day) for efficient queries
- **Compression**: 10x reduction (80MB JSON â†’ 8MB Parquet)
- **Serverless**: Event-driven Lambda processing with auto-scaling

### Machine Learning

- **Model**: Linear regression with temporal features
- **Features**: Hour of day, day of week, time index
- **Forecast Horizon**: 24 hours ahead
- **Confidence Intervals**: 95% prediction intervals using residual variance
- **Performance**: 1,715 stations forecasted in <2 minutes

### Cost Optimization

- **EC2**: t2.micro ($8/month or free tier)
- **S3**: ~$1/month for 50GB
- **Lambda**: ~$2/month for 5,000 invocations
- **Total**: ~$11/month (or $3/month with free tier)

---

## ğŸ“Š Dashboard Features

### Weather Tab
- 1,100+ weather stations with real-time temperature, humidity, wind
- Interactive map with color-coded temperature markers
- Station-specific trends and historical data
- Hot/cold weather alerts

### Water Levels Tab
- 1,500+ hydrometric stations monitoring rivers and lakes
- Real-time water level and discharge data
- **ML-based 24-hour forecasts** with confidence intervals
- Flood risk alerts (stations with >0.5m predicted rise)
- Provincial filtering

---

## ğŸ”® ML Forecasting Capabilities

The forecasting engine analyzes historical water level patterns to predict:

- **6-hour forecast**: Immediate flood risk assessment
- **24-hour forecast**: Advanced warning for resource allocation
- **Confidence intervals**: Quantified prediction uncertainty
- **Change detection**: Identifies stations with significant trends

**Example Output:**
```
âœ“ Generated forecasts for 1,715 stations
  Rising: 21 stations (water levels increasing)
  Falling: 17 stations (water levels decreasing)
  Stable: 1,677 stations (minimal change)
  High Risk: 3 stations (>0.5m rise = flood watch)
```

---

## ğŸ› ï¸ Tech Stack

**Cloud & Infrastructure:**
- Terraform(AWS Infra Provision)
- AWS S3 (data lake)
- AWS Lambda (serverless compute)
- AWS EC2 (data ingestion)
- Docker (containerization)
- AWS ECR (Container Registry)
- AWS ECS (Cluster Management)

**Data Processing:**
- Python 3.12
- Pandas (data manipulation)
- PyArrow (Parquet I/O)
- Boto3 (AWS SDK)
- Athena(Adhoc-analysis) 

**Machine Learning:**
- Scikit-learn (regression models)
- NumPy (numerical computing)

**Visualization:**
- Streamlit (dashboard framework)
- Plotly (interactive charts)

---

## ğŸ“ˆ Performance Metrics

- **Ingestion Frequency**: Every 5 minutes
- **End-to-End Latency**: <3 seconds (upload â†’ transform â†’ available)
- **Lambda Execution Time**: 400-2,750ms per batch
- **Forecast Generation**: 1,715 stations in 90 seconds
- **Dashboard Load Time**: <2 seconds
- **Data Retention**: Unlimited (S3 lifecycle policies configurable)

---

## ğŸ” Security & Best Practices

- âœ… No hardcoded credentials (IAM roles for EC2/Lambda)
- âœ… Least-privilege access policies
- âœ… Partitioned data for access control
- âœ… No KMS encryption overhead (optimized for cost)
- âœ… .gitignore prevents credential leaks

---

## ğŸ¯ Business Value

**Use Cases:**
- **Emergency Management**: Early flood warnings for municipalities
- **Infrastructure Planning**: Historical water level trends for construction
- **Agriculture**: Irrigation planning based on weather forecasts
- **Insurance**: Risk assessment for flood-prone areas
- **Environmental Monitoring**: Climate change impact analysis

---

## ï¿½ï¿½ Future Enhancements

- [ ] Add precipitation data to improve flood prediction accuracy
- [ ] Implement ARIMA/Prophet models for seasonal trends
- [ ] Deploy dashboard to AWS App Runner for public access
- [ ] Add email/SMS alerts for high-risk stations
- [ ] Historical data backfill (1+ years)
- [ ] Multi-region deployment for redundancy


## ğŸ™ Acknowledgments

- Data Source: Environment Canada (Open Government License)
- Cloud Provider: AWS
- Visualization Framework: Streamlit

---

**Built with â¤ï¸ for sustainable water management and climate resilience**
